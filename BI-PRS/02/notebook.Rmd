---
title: "BI-PRS Semestral Project 2"
authors:
  - Oleksandr Slyvka
  - Illia Lyhin
  - Maksym Khavil
output: html_document
date: "2025-04-20"
---

# Semestral Project 2

Our representative is Oleksandr Slyvka, his M-value is 6, that corresponds to scores in SAT tests, thus we will investigate its data.

## Libraries & Data

```{r setup, include=FALSE}
library(dplyr)
library(vtable)
library(ggplot2)
library(cowplot)
library(corrplot)
library(e1071)
library(tidyr)
library(plotrix)
library(car)
library(lmtest)
library(Sleuth2)
```

Load the dataset.

```{r}
data("case1201")
print(case1201)
```

## Data Description & Graphs

A comprehensive excerpt from the [manual](https://cran.r-project.org/web/packages/Sleuth2/Sleuth2.pdf):\
A data frame with 50 observations on the following 8 variables.

1.  **State** US state

2.  **SAT** state averages of the total SAT (verbal + quantitative) scores

3.  **Takers** the percentage of the total eligible students (high school seniors) in the state who took the exam

4.  **Income** the median income of families of test–takers (in hundreds of dollars)

5.  **Years** the average number of years that the test–takers had formal studies in social sciences, natural sciences and humanities

6.  **Public** the percentage of the test–takers who attended public secondary schools

7.  **Expend** the total state expenditure on secondary schools (in hundreds of dollars per student)

8.  **Rank** the median percentile ranking of the test–takers within their secondary school classes

We will need a categorical variable so let's transform **Expend**:

1.  **Low** – expenditure \< \$2000 per student

2.  **Medium** – expenditure [\$2000, \$2500) per student

3.  **High** – expenditure \>= \$2500 per student

```{r}
case1201$ExpendCat <- cut(case1201$Expend,
                          breaks = c(-Inf, 20, 25, Inf),
                          labels = c("Low", "Medium", "High"),
                          right = FALSE)
table(case1201$ExpendCat)

```

Let's display some basic descriptive statistics for each numeric column.

```{r}
case1201_numerical_cols <- subset(case1201, select = -c(State, ExpendCat))
summ <- c('mean(x)', 'sd(x)', 'skewness(x)', 'min(x)', 'pctile (x)[25]', 
          'median(x)', 'pctile(x)[75]', 'max(x)', 'IQR(x)'
)

sumtable(
  case1201_numerical_cols, colnames(case1201_numerical_cols),
  out='kable',
  summ=summ
)
```

Some interesting observations we can make are:

-   SAT scores distribution can be symmetrical.

-   Expenditure is highly skewed to the right, meaning there are some states, that spent a lot more money, than the others.

-   Takers have very high Sd, meaning high variability among regions in terms of number of test-takers.

Let's explore relationships between variables using correlation matrix:

```{r}
numeric_data <- case1201[sapply(case1201, is.numeric)]

cor_matrix <- cor(numeric_data, use = "complete.obs")

corrplot(cor_matrix, addCoef.col = "goldenrod4", tl.col = "black")
```

Our correlation insights might be:

1.  Higher test participation is linked to lower average SAT scores.

2.  States with higher income and better educational rankings and higher **Years** variable tend to have higher SAT scores.

3.  Variables like Public school percentage and Expenditure per student show weak or negligible correlations with SAT scores.

Let's visualize the distribution of the most relevant variables in the dataset.

```{r}
hist(case1201$SAT,
     main = "Distribution of SAT Scores",
     xlab = "SAT Score",
     col = "lightblue", border = "white")

hist(case1201$Takers,
     main = "Distribution of SAT Takers",
     xlab = "Number of Takers (%)",
     col = "lightgreen", border = "white")

hist(case1201$Income,
     main = "Distribution of Median Income",
     xlab = "Income ($100s)",
     col = "lightcoral", border = "white")

hist(case1201$Rank,
     main = "Distribution of Educational Rank",
     xlab = "Rank",
     col = "plum", border = "white")

```

The distributions do not appear to follow a normal distribution, however we have fairly few data points to conclude something from graphs.

Let's take a quick look on scatter plots and Pearson correlation coefficient to make some assumptions about linear trends between SAT scores and other variables.

```{r}
cor_with_sat <- cor_matrix["SAT", ]

plot(case1201$Takers, case1201$SAT,
     main = sprintf("SAT Score X %% of Test Takers (r=%.3f)", cor_with_sat["Takers"]),
     xlab = "Takers (%)",
     ylab = "SAT Score",
     col = "darkgreen", pch = 19)

plot(case1201$Income, case1201$SAT,
     main = sprintf("SAT Score X Median Income (r=%.3f)", cor_with_sat["Income"]),
     xlab = "Income ($100s)",
     ylab = "SAT Score",
     col = "orangered", pch = 19)

plot(case1201$Rank, case1201$SAT,
     main = sprintf("SAT Score X Secondary School Rank (r=%.3f)", cor_with_sat["Rank"]),
     xlab = "Rank",
     ylab = "SAT Score",
     col = "purple", pch = 19)

plot(case1201$Years, case1201$SAT,
     main = sprintf("SAT Score X Average Years of Education (r=%.3f)", cor_with_sat["Years"]),
     xlab = "Years of Education",
     ylab = "SAT Score",
     col = "orange", pch = 19)

```

Based on the plots above and strong enough positive correlation coefficient **(0.88)** we chose **Rank** as a regressor for the second task.

## Numerical Regressor

We will compare the linear and quadratic regression models to determine which better explains the relationship between SAT and Rank.

```{r}
model_lin <- lm(SAT ~ Rank, data = case1201)
summary(model_lin)
```

```{r}
model_quad <- lm(SAT ~ Rank + I(Rank^2), data = case1201)
summary(model_quad)
```

Let's plot the regression line and curve so we have a broader picture.

```{r}
plot(case1201$Rank, case1201$SAT,
     main = "SAT vs. Rank with Linear and Quadratic Fit",
     xlab = "Rank", ylab = "SAT Score",
     pch = 19, col = "gray")

abline(model_lin, col = "blue", lwd = 3)

x_vals <- seq(min(case1201$Rank), max(case1201$Rank), length.out = 100)
y_vals_quad <- predict(model_quad, newdata = data.frame(Rank = x_vals))
lines(x_vals, y_vals_quad, col = "red", lwd = 3)

legend("bottomright",
       legend = c("Linear Fit", "Quadratic Fit"),
       col = c("blue", "red"), lwd = 2)
```

Now we have to choose which model to use. **Linear Model** is great, mainly because it's interpretation is very clear: *for each 1-point increase in Rank, the SAT score increases by \~9.56 points*. *Intercept means that the SAT score of person with 0 point Rank may be predicted as \~183 points.*

Both of the models explain high portion of variability in data, however **Quadratic Model** has a slightly better fit (Adjusted R² = 0.779 vs. 0.769). None of its coefficient are statistically significant, so despite having better adjusted R² it should be reducible to **Linear Model**. We can use ANOVA which helps us to test:

$$
H_0: \text{The additional predictors in Quadratic Model do not improve the model.}\\
H_A: \text{At least one of the additional predictors in Quadratic Model has a non-zero coefficient.}
$$

```{r}
anova(model_lin, model_quad)
```

Under significance level of $α=0.05$ we fail to reject the null hypothesis. So we can choose **Linear Model**.

## Categorical Regressor

**ExpendCat** will be used as categorical regressor. First we will apply analysis of variance on it to compare the means of SAT score in different categories. So let's examine SAT score distributions in each category:

```{r}
boxplot(SAT ~ ExpendCat, data = case1201,
        main = "SAT Scores by Expenditure Category",
        xlab = "Expenditure Category", ylab = "SAT Score",
        col = c("lightblue", "lightgreen", "lightcoral"))
means <- tapply(case1201$SAT,case1201$ExpendCat,mean)
points(means,col="black",pch=17)
legend("bottomright", pch=17, "Means of Categories")
```

It is hard to tell if the means (indicated by triangles on the box-plots) are statistically significantly different, **High** category only shows, that disribution there is skewed. So we will apply analysis of variance on **ExpendCat** to test:

$$
H_0: \text{The mean SAT scores are the same across all categories.}\\
H_A: \text{At least two ExpendCat categories have different SAT scores means.}
$$

```{r}
anova(aov(SAT ~ ExpendCat, data = case1201))
```

The *p-value* is much greater than $0.05$, thus the result is not statistically significant and we fail to reject the null hypothesis. The ANOVA test shows that **ExpendCat** does not significantly affect SAT scores (SAT scores do not differ meaningfully between low, medium, and high-expenditure groups).

Next we will see how bad will be predictions with such regressor.

```{r}
fit=lm(SAT ~ ExpendCat, data = case1201)
summary(fit)
```

Coefficients:

-   **Intercept**: This is the average SAT score for states (944.94) in the Low expenditure category.

-   **ExpendCatMedium**: On average, SAT scores in the Medium category are only \~11 points higher than in the Low category, but this difference **is not statistically significant**.

-   **ExpendCatHigh**: SAT scores in the High expenditure category are very slightly lower (by \~1 point) than the Low category, **and this is also not significant**.

So the model also suggests that total state expenditure on secondary schools has no real effect on average SAT scores. Also the model itself is poor, **Adjusted R-squared is negative**, meaning the model performs worse than a mean-only model.

## Interaction Model

Now we use both of the above regressors together.

```{r}
interaction_model <- lm(SAT ~ Rank * ExpendCat, data = case1201)
summary(interaction_model)
```

Coefficients now are a bit harder to interpret:

-   **Intercept**: Baseline SAT score (–139.45) when Rank = 0 and ExpendCat = Low. However score can not be negative.

-   **Rank**: For Low expenditure states, each additional point in Rank increases SAT by \~13.1 points.

-   **ExpendCatMedium**: Medium-expenditure states have \~289 points higher SAT than Low-expenditure ones if Rank = 0 (intercept shift).

-   **ExpendCatHigh**: High-expenditure states have \~368 points higher SAT than Low-expenditure ones if Rank = 0.

-   **Rank:ExpendCatMedium**: The positive effect of Rank is slightly weaker (–3 pts) in Medium group compared to Low.

-   **Rank:ExpendCatHigh**: The effect of Rank is even weaker in High group (–3.94 pts compared to Low).

Statistical Significance:

-   **Rank** alone is the most significant one component here.

-   **ExpendCat (Medium and High)** significantly shifts the baseline SAT score up (with Rank = 0), though the intercept itself not much meaningful in isolation.

-   **Interaction with High** is clearly significant, confirming that expenditure level modifies the influence of Rank on SAT.

-   **Interaction with Medium** is marginally significant.

**Adjusted R²** is **0.868**, meaning that this model gives a **better explanation** of SAT variation than linear regression with **Rank** alone.

Let's visualize regression lines for different **ExpendCat** categories.

```{r}
ggplot(case1201, aes(x = Rank, y = SAT, color = ExpendCat)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x,se = FALSE) +
  labs(title = "Interaction: SAT ~ Rank * ExpendCat",
       x = "Educational Rank", y = "SAT Score")

```

We see how much scores differ for **Low** category.

## Model with three Regressors

As addition to the previous regressors we will add **Takers**, because it is highly correlated with SAT scores.

```{r}
full_model <- lm(SAT ~ Rank * ExpendCat * Takers, data = case1201)
summary(full_model)
```

We observe that Adjusted R-squared improved a lot. But the coefficients became unstable (high standard error) and insignificant. So we can try to reduce this model to a submodel using function `step()`, which goes through the variables step by step and If it encounters one whose inclusion reduces the AIC, it will add it to the model and continue until the optimal version is reached:

```{r}
step(lm(SAT ~ 1, data = case1201), 
     scope = list(lower = ~ 1, upper = ~ Rank * ExpendCat * Takers), 
     direction = "both", 
     data = case1201)
```

Model with the lowest AIC found is

`SAT ~ Rank + ExpendCat + Takers + Rank:Takers + ExpendCat:Takers`

The `step()` function uses a greedy approach, so maybe we did not get a model with the best AIC, but we see, that terms number was significantly reduced. Let's fit the model and see how statistics for it changed, compared to previous model.

```{r}
final_model <- lm(formula = SAT ~ Rank + ExpendCat + Takers + Rank:Takers + 
    ExpendCat:Takers, data = case1201)
summary(final_model)
```

The final model has slightly higher Adjusted R-squared with lower Multiple R-squared. Most of the coefficients are significant and in this case unlike the model with just **Rank** and **ExpendCat** we see that the model is better interpretable:

-   **Intercept**: Baseline SAT score is 278.62 when Rank is 0, ExpendCat is Low, Takers is 0%.

-   **Rank**: Each rank increase raises SAT score by 8.55 points.

-   **ExpendCatMedium**: Schools with medium expenditure have SAT scores 22.55 points higher than low-expenditure schools.

-   **ExpendCatHigh**: High-expenditure schools have SAT scores 36.06 points higher than low-expenditure schools.

-   **Takers**: Each additional percent of test-takers increases SAT score by 10.42 points.

-   **Rank**:**Takers**: As test-takers increase, the effect of Rank on SAT scores decreases by 0.16 points.

-   **ExpendCatMedium:Takers**: In medium-expenditure schools, each additional test-takers percent increases SAT score by 0.92 points more than in low-expenditure schools.

-   **ExpendCatHigh:Takers**: In high-expenditure schools, each additional test-taker increases SAT score by 0.60 points, but this effect is not significant.

As previously let's test if model and submodel have the same power.

```{r}
anova(final_model, full_model)
```

High p-value shows, that we can not say that full model is better, and we can use smaller, better interpretable one.

## Testing the assumptions

Use of linear model has several assumptions:

-   **Linearity** (we checked it with graphs)

-   **Independence** of observations (is trusted from Sleuth2)

-   **Normality** of the residuals

-   **Homoscedasticity** of the residuals

-   **No outliers** in the data

-   **No Multicollinearity**

The last four should be yet verified.

We also used `anova` for comparing model and it's nested model. This test requires residuals of the full model to be normal. Since normality of residuals is one of the assumptions for using a linear model, if this assumption holds, the use of ANOVA for model comparison was also justified.

### Normality

Let's visualize the residuals.

```{r}
plot(final_model, which=1)
```

Looks like residual values are more frequent near zero. But there are many values far from zero also, let's study standardized distribution with Q-Q plot

```{r}
plot(final_model, which=2)
```

From the plots we see that distribution has heavy tails, however they are not critical. To reach some formal conclusion we will test residuals for normality with Shapiro-Wilk test.

```{r}
shapiro.test(final_model$residuals)
```

Null hypothesis is that **distribution of the residuals is normal** and with that high p-value it is not rejected.

### Homoscedasticity

```{r}
plot(final_model, which=3)
```

The red approximation line slightly increases with time, so maybe we still have homoscedastic data. Let us formulate hypotheses for further test.

$$
H_0: \text{Residuals have constant variance (Homoscedasticity)}\\
H_A: \text{Residuals' variance raise with regressand values (Heteroscedasticity)}
$$

We can conduct Breusch-Pagan test to check these hypotheses.

```{r}
bptest(final_model)
```

High p-value is a sign, that we do not reject the null hypothesis, that the **residuals have constant variance.**

### Outliers

We can take a look at cook's distance which say how different observation affect our model.

```{r}
plot(final_model, which=4)
```


Let us take a look on the samples that are discussed.
```{r}
largest_cookd <-  case1201[c(28, 47, 50),]
largest_cookd$modeled_SAT <-  predict(final_model, newdata=largest_cookd)
largest_cookd <- largest_cookd[c("State", "SAT", "modeled_SAT")]
largest_cookd
```
We see three outliers, but it is hard to tell how strong their effect is compared to other observations, so we will plot their leverage.

```{r}
plot(final_model, which=5)
```

Observation with number $47$ lies closest to the border of Cook’s distance, but it doesn’t fall outside of the dashed line. This means **there are no influential points** in our regression model. Sample $47$ is Hawaii, a state far away from continent and the latest addition to union, so it is an "outlier" in USA not only SAT score regression.

### Multicolinearity

An overview of how much each regressor depends on the others is provided by the **variance inflation factor**, which indicates how well the j-th regressor is explained by the other predictors. In our case, however, we will use **adjusted** **generalized VIF**, because we a have factor variable.

```{r}
vif(final_model, type = "predictor")
```

All adjusted GVIF values are $<2$ which in literature is considered a good result, which indicates, that the **colinearity is weak**.

## Conclusion

Our final selection of regressors resulted in a linear model that effectively captured the structure of the data, while also satisfying all the assumptions necessary for its validity, which is really surprising. This model can be used to predict SAT scores in a state only with knowledge about **Rank**, **ExpendCat**, **Takers** with high R2 score, which is great.
