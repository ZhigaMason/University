{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c544ef19-a9a8-45de-a3eb-8b7bbcafa8e1",
   "metadata": {},
   "source": [
    "# Cvičení 5 - naivní Bayesův klasifikátor\n",
    "\n",
    "V dnešním cvičení se budeme zabývat řešením problému klasifikace pomocí metody nazývané naivní Bayesův klasifikátor (Naive Bayes).\n",
    "\n",
    "Pro data s diskrétními hodnotami příznaků je MAP odhad predikované proměnné $Y$ naivního Bayesova klasifikátoru roven\n",
    "\n",
    "$$\n",
    "\\hat Y = \\arg \\max_{y \\in \\mathcal Y} \\prod_{i = 1}^p P(X_i = x_i | Y = y) P(Y = y).\n",
    "$$\n",
    "\n",
    "Dokumentace a příklady pro dostupné metody ve `scikit-learn` jsou [zde](https://scikit-learn.org/stable/modules/naive_bayes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0d9fb-11b8-4093-b18e-26794e56a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087a73d-5791-4441-9b5d-25c3f7ae92ef",
   "metadata": {},
   "source": [
    "## Binární příznaky - Bernoulliho rozdělení podmíněné pravděpodobnosti\n",
    "\n",
    "Zabývejme se nyní situací s binární klasifikace s binárními příznaky. V takovém případě \n",
    "podmíněné pravděpodobnosti $P(X = x | Y = y)$ pro příznak $X$ mají Bernoulliho rozdělení s parametrem $p_y = P(X = 1|Y = y)$.\n",
    "\n",
    "Uvažujme jako na přednášce data obsahující tři binární příznaky $X_1, X_2, X_3$ a binární vysvětlovanou proměnnou $Y$\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc}\n",
    "          Y & X_1 & X_2 & X_3 \\\\\n",
    "          \\hline\n",
    "          1 & 1 & 1 & 0 \\\\\n",
    "          1 & 0 & 1 & 1 \\\\\n",
    "          1 & 1 & 1 & 1 \\\\\n",
    "          1 & 1 & 0 & 1 \\\\\n",
    "          0 & 0 & 1 & 0 \\\\\n",
    "          0 & 1 & 0 & 0 \\\\\n",
    "        \\end{array}\n",
    "$$\n",
    "\n",
    "Data byla generována tak, že ve skutečnosti jsou $X_1, X_2, X_3$ nezávislé veličiny se stejným rovnoměrným rozdělením,\n",
    "$X_i \\sim Be(1/2)$, a $Y = 1$ právě, když jsou alespoň dvě hodnoty příznaků rovny $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe1859-4268-4ade-ac46-156ba389d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [1,1,0],\n",
    "    [0,1,1],\n",
    "    [1,1,1],\n",
    "    [1,0,1],\n",
    "    [0,1,0],\n",
    "    [1,0,0],\n",
    "])\n",
    "Y = np.array([1,1,1,1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da9b81-55cd-4226-b4c4-7d8c7e4b1ca0",
   "metadata": {},
   "source": [
    "Implementace `BernoulliNB(*, alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)` v knihovně scikit-learn nám umožní model rovnou natrénovat jelikož příznaky jsou již binární. Pokud tomu tak není, lze zadat parametr `binarize` určující hranici pro reprezentaci dat pomocí $0$ a $1$. \n",
    "\n",
    "Při výchozí volbě parametru `alpha = 1.0` se aposteriorní rozdělení, tj. odhady parametru $p_y$, počítají jako\n",
    "\n",
    "$$\n",
    "\\hat p_y = \\frac{N_{1,y} + 1}{N_{1,y} + N_{0,y} + 2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17143aa8-dd89-4588-a930-087a3d8578d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB();\n",
    "clf.fit(X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546eda5-9e8c-4380-8742-533a9d3ec50c",
   "metadata": {},
   "source": [
    "### Odhady parametrů Bernoulliho rozdělení\n",
    "Nejprve se podívejme na odhadnuté parametry Bernoulliho rozdělení vysvětlované proměnné a jednotlivých příznaků a na způsob, jakým byly spočteny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db055c83-0cbd-4322-ae87-e285105efd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Třídy y:', clf.classes_)\n",
    "print('Počty vzorků pro každou třídu:',clf.class_count_)\n",
    "print(f\"\\nOdhady pravděpodobnosti jednotlivých tříd: {np.exp(clf.class_log_prior_)}\")\n",
    "print(f\"\\nRuční odhad pravděpodobnosti P(Y = 1): {Y.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb8bd7-b910-4f75-8433-61c50842ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Počty pozitivních vzorků pro každou třídu a příznak:\\n', clf.feature_count_)\n",
    "print(f\"\\nOdhady parametrů pro každý příznak a každou třídu:\\n{np.exp(clf.feature_log_prob_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b9826-9730-4dcf-95a8-c3b30b7c2929",
   "metadata": {},
   "source": [
    "### Spočtěte odhady parametrů $p_y$ ručně\n",
    "\n",
    "Použijte standardní odhady $p_y = P(X = 1 | Y = y)$ a potom vyhlazení pomocí Laplaceova pravidla\n",
    "\n",
    "$$\n",
    "\\hat p_y = \\frac{N_{1,y} + 1}{N_{1,y} + N_{0,y} + 2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956206f-86a9-44bf-99af-5fe049e4eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váš kód zde\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5fcec-cc63-4441-9afa-de3392f55f69",
   "metadata": {},
   "source": [
    "### MAP odhad\n",
    "Odhady pravděpodobností \n",
    "$$\n",
    "P(Y = y | \\boldsymbol X = \\boldsymbol x) = \\frac{\\prod_{i = 1}^p P(X_i = x_i | Y = y) P(Y = y)}{P(\\boldsymbol X = \\boldsymbol x)}\n",
    "$$ \n",
    "a výsledná predikce na trénovací množině."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933e504-4c5c-4ce0-99b6-811586f0f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Odhad pravděpodobnosti pro vektory X:\\n',clf.predict_proba(X))\n",
    "\n",
    "print(f\"\\nPredikce pro vektory X:\\n{clf.predict(X)}\")\n",
    "print(f\"Skutečné Y:\\n{Y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084efb7-bc9e-4ab7-87bf-77d7bac834cc",
   "metadata": {},
   "source": [
    "### Predikce pro nová data\n",
    "Nyní přistupme k predikci pro vektory $\\{(0,0,1)^T,(0,0,0)^T\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57678651-954d-4731-a8ac-54f81590fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = np.array([[0,0,1],[0,0,0]])\n",
    "ytest = np.array([0,0])\n",
    "print('Odhady pravděpodobností jsou:\\n',clf.predict_proba(Xtest))\n",
    "print('\\nTedy vektory klasifikujeme jako:\\n',clf.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034358ca-a027-474d-80a5-5a9ac9029229",
   "metadata": {},
   "source": [
    "### Vyzkoušejte vliv vyhlazování pomocí parametru alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3567192-b51f-460a-aeca-773398d99762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váš kód zde\n",
    "\n",
    "alpha = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa9101-98a9-4a7d-88f8-c8e95972ab71",
   "metadata": {},
   "source": [
    "## Spojité příznaky - (Gaussovo) normální rozdělení podmíněné pravděpodobnosti\n",
    "\n",
    "Nyní se budeme zabývat situací, kdy mají příznaky spojité rozdělení. V takovém případě je sdružené rozdělení $\\boldsymbol X, Y$ smíšené, což moc nevíme co je. Podmíněná rozdělení jednotlivých příznaků jsou ale zase spojitá a tedy použijeme stejné vzorečky akorát místo pravděpodobností jednotlivých hodnot pro $X$ tam budeme mít hustoty.\n",
    "\n",
    "MAP odhad predikované proměnné $Y$ naivního Bayesova klasifikátoru tedy bude roven\n",
    "\n",
    "$$\n",
    "\\hat Y = \\arg \\max_{y \\in \\mathcal Y} \\prod_{i = 1}^p f_{X_i|y}(x_i) P(Y = y),\n",
    "$$\n",
    "\n",
    "kde $f_{X_i |y}(x_i)$ je hustota podmíněného rozdělení $X_i | Y = y$.\n",
    "\n",
    "Běžně uvažovaným modelem pro spojité podmíněné rozdělení příznaků je normální rozdělení. Ve `scikit-learn` je implementováno v metodě [GaussianN](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html).\n",
    "\n",
    "Pro každý příznak podmíněno hodnotu $Y = y$ se tak odhadují dva parametry - střední hodnota $\\mu_y$ a rozptyl $\\sigma_y^2$. Podmíněná hustota je pak dána vztahem\n",
    "\n",
    "$$\n",
    "f_{X |y}(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y^2}} e^{-\\frac{1}{2\\sigma_y^2}(x - \\mu_y)^2}\n",
    "$$\n",
    "\n",
    "### Klasifikace Iris datasetu\n",
    "použití tohoto modelu si otestujeme na známem datasetu [Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set), který již známe ze 4. cvičení BI-ML1.\n",
    "\n",
    "Teto dataset obsahuje záznamy o šířkách a délkách korunních (petal) a kališních (sepal) lístků kosatců. V datasetu se vyskytují tři druhy kosatců (setosa, versicolor a virginica) a cílem je klasifikovat na základě těchto 4 příznaků o jaký druh se jedná.\n",
    "\n",
    "Dataset načteme pomocí modulu `sklearn.datasets`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b823e-f26a-4f5d-a76c-09dc323f50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "random_seed = 42\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "print(f\"Train rozměry, X: {Xtrain.shape}, y: {ytrain.shape}\")\n",
    "print(f\"Val rozměry, X: {Xval.shape}, y: {yval.shape}\")\n",
    "\n",
    "print('Ukázka dat:')\n",
    "display(Xtrain[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b65e3-ebda-4c8e-a2e6-1d9edae2a4b5",
   "metadata": {},
   "source": [
    "Vykreslíme si histogramy hodnot jednotlivých příznaků $X_{train}$ v trénovací množině."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2dc30a-428b-4be1-b9b7-d7f8f44565d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10));\n",
    "plt.subplot(221); plt.title('rozdělení X_1'); plt.hist(Xtrain[:,0],bins=10);\n",
    "plt.subplot(222); plt.title('rozdělení X_2'); plt.hist(Xtrain[:,1],bins=20);\n",
    "plt.subplot(223); plt.title('rozdělení X_3'); plt.hist(Xtrain[:,2],bins=20);\n",
    "plt.subplot(224); plt.title('rozdělení X_4'); plt.hist(Xtrain[:,3],bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e0184-b15e-4b6d-a1d0-842a3d4d1262",
   "metadata": {},
   "source": [
    "Z histogramů není jasné jaké rozdělení by příznaky $X_i$ mohly mít, tedy jaká by měla být hustota pravděpodobnosti $f_{X_i|y}(x_i)$. Částečně za to může i fakt se kterým jsme se setkali dříve, totiž že v datasetu se jedna třída od ostatních viditelně liší (v histogramu bude více vrcholů).\n",
    "\n",
    "Tím, že nás ale zajímají podmíněná rozdělení, nemusíme se nutně trápit tím, že nepodmíněná rozdělení nevypadají Gaussovsky.\n",
    "\n",
    "Příslušné histogramy pro jednotlivé třídy můžeme získat tak, že v předchozím nahradíme `Xtrain` pomocí `Xtrain[ytrain == i]`. Situace se tím trochu zlepší, ale dat potom není mnoho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00683373-b044-4206-8eef-d3455cc13823",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "# Váš kód zde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7287569a-9c54-4ffe-926f-19acf43a2497",
   "metadata": {},
   "source": [
    "### Použití sklearn implementace\n",
    "\n",
    "Nyní využijeme `GaussianNB` ze `scikit-learn`, který příslušné podmíněné hustoty odhaduje.\n",
    "\n",
    "Odhady střední hodnoty a rozptylu, které počítá, jsou dány vztahy\n",
    "$$\n",
    "\\hat \\mu_y = \\frac{1}{N_y}\\sum_{i}^{N_y} x_i, \\quad \\hat \\sigma^2_y = \\frac{1}{N_y}\\sum_{i}^{N_y} (x_i - \\hat \\mu_y)^2,\n",
    "$$\n",
    "kde $x_1,\\dotsc,x_{N_y}$ jsou hodnoty příznaku $X$, pro které $Y = y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd23c8-237f-437f-abff-f44b2b601add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB();\n",
    "clf.fit(Xtrain, ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591f2a2-0922-467d-8057-2aa5d4da1f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Třídy y:', clf.classes_)\n",
    "print('Počet vzorků pro každou třídu:',clf.class_count_)\n",
    "print(f\"\\nOdhady pravděpodobnosti jednotlivých tříd: {clf.class_prior_}\")\n",
    "print(f\"\\nOdhad podmíněné střední hodnoty pro každou třídu a příznak:\\n{clf.theta_}\")\n",
    "print(f\"\\nOdhad rozptylu pro každou třídu a příznak:\\n{clf.var_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f1d0a2-0c01-4b05-8b14-dfbe43dbf0b5",
   "metadata": {},
   "source": [
    "### Ruční výpočet\n",
    "\n",
    "Ověřte, že se jedná o odhady podle uvedených vztahů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2dcc29-d064-4599-933a-f89c888aa130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váš kód zde\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414a317-f370-45c7-8eba-5daaa5e1d712",
   "metadata": {},
   "source": [
    "### Úspěšnost predikce\n",
    "\n",
    "Vyzkoušíme úspěšnost predikce na trénovací a testovací množině."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ac193-f568-409f-beb8-85317817a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Trénovací přesnost modelu je {clf.score(Xtrain, ytrain):.4f}\")\n",
    "\n",
    "print(f\"\\nValidační přesnost modelu je {clf.score(Xval, yval):.4f}\")\n",
    "ypred = clf.predict(Xval)\n",
    "print(f\"Z {Xval.shape[0]} bodů v Xval je špatně klasifikovaných: {(yval != ypred).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e594478-8da7-442f-8c56-97ed460758ab",
   "metadata": {},
   "source": [
    "### Porovnání s jinými klasifikačními modely\n",
    "\n",
    "Podívejme se na další klasifikační modely a jak si stojí při predikci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1554c1-b606-41a0-b016-10da4ce474c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Min-max scaler nafitujeme na trénovacích datech\n",
    "scaler = StandardScaler()\n",
    "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# Následně stejnou transformaci aplikujeme i na validační data\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "clf.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "print(f\"Testovací přesnost KNN: {clf.score(Xval_scaled, yval):0.4f}\")\n",
    "\n",
    "# náhodný les\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state = 42)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "print(f\"Testovací přesnost náhodného lesa: {clf.score(Xval, yval):0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6ac3f-af92-4d81-b0ce-12802c93090f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
